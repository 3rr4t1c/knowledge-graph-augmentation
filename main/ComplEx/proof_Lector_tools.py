import numpy as np
import random
from dataset import Dataset
import requests
from bs4 import BeautifulSoup

# Choosen relations (must match with existing ones)
EXAMPLE_TARGET_RELATIONS = ['/people/person/spouse_s./people/marriage/spouse',
                            '/people/person/place_of_birth' ]

# Example map. phrase -> (0 if bad phrase / 1 if good phrase, index of target relation)
EXAMPLE_PHRASE2RELATIONS = {'married on': (1, 0),
                            'met': (0, 0),
                            'married to': (1, 0),
                            'become engaged': (0, 0), 
                            'was born in': (1, 1),
                            'worked in': (0, 1),
                            'lived in': (0, 1),
                            'born in': (1, 1)}
# This map act like a hint just for build the phrase2facts map. 
# In real cases I don't know if a phrase is good or bad.

# Generate a list of facts (triples) of same relation, 
# sampling from list of instances, with some corrupted facts.
# relation is a string, instance is a list, true_amount and corrupted_amount are integers
def generate_facts(relation, instances, true_amount, corrupted_amount):
    # List with all correct facts as triples
    facts = [(h, relation, t) for h, t in random.sample(instances, true_amount)]
    # Generate corrupted facts
    for _ in range(corrupted_amount):
        i1, i2 = random.sample(instances, 2)
        corrupted_fact = (i1[0], relation, i2[1]) # Pylint unsubscriptable error is a false positive
        facts.append(corrupted_fact)    
    
    return facts

# A map: phrase -> list of facts will be generated to simulate the behaviour of Lector in phrase tracking
# The facts_file can be any file containing one facts per row as a triple
# The target_relations is a list of relations of interest in string format 
# phrase2relation is a map where: phrase -> (0 if bad phrase / 1 if good phrase, relation index)
# Note: A hint of what phrases is good and bad is necessary to simulate the real behaviour
def generate_phrase2facts(facts_file, target_relations, phrase2relation):
    phrase2facts = dict()

    # Read facts file selecting all target relations facts
    relation2instances = dict() # No-redundancy structure for storing facts by relations
    with open(facts_file, 'r') as f:
        for line in f:
            h, r, t = line.strip().split()
            if r in target_relations:
                try:
                    relation2instances[r].append((h, t))
                except:
                    relation2instances[r] = []
                    relation2instances[r].append((h, t))
    
    # Randomly distribute facts (true positive) along all matching phrases with duplicates
    # Inject some random false facts generated by shuffling heads and tails of same relation
    for phrase, (v, r) in phrase2relation.items():
        # The corresponding relation string descriptor
        relation = target_relations[r]
        # All the instances of relation
        instances = relation2instances[relation]
        # Number of true facts (e.g. Barack spuse Michell) to generate
        true_amount = np.random.randint(1, len(instances)//2)
        # Number of corrupted facts (e.g. Barack spouse Trump) to generate
        corrupted_amount = np.random.randint(true_amount, true_amount*2) if v == 0 else 0
        # Generate a list of facts associated to the current phrase
        phrase2facts[phrase] = generate_facts(relation, instances, true_amount, corrupted_amount)
    
    return phrase2facts


# Return the real name of and entity by FreeBase mID
def mID_resolve(mID):
    r = requests.get('https://cofactor.io' + mID)
    soup = BeautifulSoup(r.text, 'html.parser')
    return soup.title.get_text()


# Require a kg to encode
def facts2samples_encoder(facts, kg):
    samples = []
    for h, r, t in facts:
        samples.append((kg.entity_name_2_id[h], kg.relation_name_2_id[r], kg.entity_name_2_id[t]))
    return samples



## TEST AREA ##
if __name__ == '__main__':

    # Load dataset
    print('Loading dataset...', end='', flush=True)
    kg = Dataset(name='FB15k-237')
    print('Done.')    
    fb_relations = kg.relations
    
    # Print all relations
    for r in fb_relations:
        print(r)  
    
    print(len(fb_relations), ' relazioni totali.\n')
    
    p2f = generate_phrase2facts('data/FB15k-237/test.txt', EXAMPLE_TARGET_RELATIONS, EXAMPLE_PHRASE2RELATIONS)
    p2s = {k: facts2samples_encoder(v, kg) for k, v in p2f.items()}
    
    # Print the result
    for k, v in p2s.items():
        print(k, 'V V V V V' )
        for t in v:
            print(t)
        print()

